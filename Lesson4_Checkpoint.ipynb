{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdRd8CwdZ85r1Kv50BVPJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanGMONeill/nlpworkshop_instructor/blob/main/Lesson4_Checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kzhyDh-TBnR",
        "outputId": "07513694-5163-4cab-fff9-a64373b68604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chatterbot-corpus in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
            "Collecting levenshtein\n",
            "  Downloading Levenshtein-0.20.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<4.0,>=3.12 in /usr/local/lib/python3.8/dist-packages (from chatterbot-corpus) (3.13)\n",
            "Collecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein\n",
            "Successfully installed levenshtein-0.20.9 rapidfuzz-2.13.7\n"
          ]
        }
      ],
      "source": [
        "# This command will install chatterbot-corpus, a library which contains a corpus of conversations in YAML format\n",
        "# You can view these raw files in the chatterbot-corpus GitHub repo: https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/english\n",
        "!pip install chatterbot-corpus levenshtein\n",
        "\n",
        "import chatterbot_corpus\n",
        "from yaml import load\n",
        "import inspect\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the run variable to True\n",
        "run = True\n",
        "\n",
        "def tokenize(msg):\n",
        "  msg = msg.lower()\n",
        "  tokens = msg.split(' ')\n",
        "  return tokens\n",
        "\n",
        "\n",
        "def remove_punctuation(msg):\n",
        "  symbols = ['?','-',',',':',';','!']\n",
        "  for symbol in symbols:\n",
        "    msg = msg.replace(symbol, '')\n",
        "  return msg\n",
        "\n",
        "elements = {\n",
        "    'hydrogen': 1,\n",
        "    'oxygen': 8,\n",
        "    'carbon': 3,\n",
        "    'plutonium': 94,\n",
        "    'helium': 2,\n",
        "    'lithium': 3\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_text(msg):\n",
        "  msg = msg.lower()\n",
        "  symbols = ['?','-',',',':',';']\n",
        "  for symbol in symbols:\n",
        "    msg = msg.replace(symbol, '')\n",
        "  return msg\n",
        "\n",
        "\n",
        "def choose_response(msg):\n",
        "  try:\n",
        "\n",
        "    # Fetch the list of possible responses\n",
        "    options = lookup[normalize_text(msg)]\n",
        "    # Return a randomly selected item from the list (using the Python random library)\n",
        "    return random.choice(options)\n",
        "\n",
        "  # Handle the case where the input isn't in the dictionary\n",
        "  except KeyError:\n",
        "    return None\n",
        "\n",
        "# Find distance between two strings\n",
        "# Using this to abstract away the library calls, so we can quickly swap out Levenshtein and Jaro Winkler in one place\n",
        "def find_distance(string1, string2):\n",
        "  return Levenshtein.distance(string1, string2)\n",
        "\n",
        "# Find the string from options which has the shortest distance to input\n",
        "# input is a cleaned input string\n",
        "# options is a list of cleaned strings\n",
        "def find_shortest_distance(input, options):\n",
        "  shortest_distance = math.inf # Initialize to infinity to start\n",
        "  string_with_shortest_distance = ''\n",
        "  for option in options:\n",
        "    distance = find_distance(input, option)\n",
        "    if distance < shortest_distance:\n",
        "      shortest_distance = distance\n",
        "      string_with_shortest_distance = option\n",
        "  return string_with_shortest_distance\n",
        "\n",
        "\n",
        "# Create a dict of msg->response from the files in the corpus\n",
        "def load_conversations_from_corpus():\n",
        "  # 1) Get the location of the corpus YAML files installed with the chatterbot corpus package\n",
        "  data_path = os.path.join(os.path.dirname(inspect.getfile(chatterbot_corpus)), 'data/english')\n",
        "\n",
        "  # 2) Build a list of conversations (each file is a full conversation)\n",
        "  conversations = []\n",
        "  for file in os.listdir(data_path):\n",
        "    convos = load(open(os.path.join(data_path, file), 'r'))\n",
        "    conversations = conversations + convos['conversations']\n",
        "\n",
        "  # 3) Build a dictionary of all the msg->[response] pairs in every conversation\n",
        "  lookup = {}\n",
        "  for convo in conversations:\n",
        "    lookup[normalize_text(convo.pop(0))] = convo # Note we're now normalizing the dictionary key. We're keeping the responses in their original case, with punctuation.\n",
        "  return lookup\n",
        "\n",
        "lookup = load_conversations_from_corpus()\n",
        "\n",
        "\n",
        "# While run is still True, loop through the rest of the script\n",
        "while run:\n",
        "  # Wait for the user to input text, and store it in the msg variable\n",
        "  msg = input().lower()\n",
        "  msg = remove_punctuation(msg)\n",
        "  tokens = tokenize(msg)\n",
        "  # Give a response, based on the input (if we recognise it)\n",
        "  if msg == 'exit':\n",
        "    print('Goodbye!')\n",
        "    # Set run to False, so the loop won't run again\n",
        "    # This means we won't be trapped in an infinite loop\n",
        "    run = False\n",
        "  elif msg == 'hello':\n",
        "    print('Hi!')\n",
        "  elif msg == 'how are you':\n",
        "    print('I\\'m pretty good, thanks!')\n",
        "  elif 'rain' in tokens:\n",
        "    print('I love rain!')\n",
        "  elif 'atomic number' in msg:\n",
        "    found_element = False\n",
        "    for token in tokens:\n",
        "      if token in elements:\n",
        "        print('The atomic number for {element} is {symbol}'.format(element=token, symbol=elements[token]))\n",
        "        found_element = True\n",
        "    if not found_element:\n",
        "      print('You asked about an atomic number, but I don\\'t recognise an element name in your message')\n",
        "  # If the input doesn't match any of our statements, print a generic answer\n",
        "  else:\n",
        "    closest_input = find_shortest_distance(msg, lookup.keys()) # keys from lookup is a list of the input strings from the corpus\n",
        "    print('Closest input: {}'.format(closest_input))\n",
        "    print(choose_response(closest_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCjZBZAETPJx",
        "outputId": "4e187c3b-37d0-440b-b9ef-78579e03a0f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello!\n",
            "Hi!\n",
            "How are you?\n",
            "I'm pretty good, thanks!\n",
            "What is a computer?\n",
            "Closest input: what is a computer\n",
            "A device which maps one set of numbers onto another set of numbers.\n",
            "What's a number?\n",
            "Closest input: what is your number\n",
            "23 skiddoo!\n",
            "What's a computer?\n",
            "Closest input: what is a computer\n",
            "An electronic device capable of performing calculations at very high speed and with very high accuracy.\n",
            "exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}